{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a0d56a-0c1d-4f62-b9a9-ebfc9f34dd02",
   "metadata": {},
   "source": [
    "## Import & Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ab6a41-2b24-4b3d-894c-929339e7891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import bisect\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import timedelta\n",
    "\n",
    "train = pd.read_csv('train.csv').drop(columns=['SAMPLE_ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e91bc-96c4-4b01-9b66-ece6130feefc",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951a14a6-7513-4a98-a827-d33e066a7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding features: 100%|██████████| 6/6 [00:01<00:00,  5.29it/s]\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "##시간 데이터 처리\n",
    "# datetime 컬럼 처리\n",
    "train['ATA'] = pd.to_datetime(train['ATA'])\n",
    "test['ATA'] = pd.to_datetime(test['ATA'])\n",
    "\n",
    "# UTC와 local 간 시차 계산\n",
    "train['hour'] = train['ATA'].dt.hour #ATA 시간 추출\n",
    "test['hour'] = test['ATA'].dt.hour\n",
    "\n",
    "train['TIME_DIFFERENCE'] = train['ATA_LT'] - train['hour'] #시차 계산\n",
    "train['TIME_DIFFERENCE'] = train['TIME_DIFFERENCE'].apply(lambda x: x+24 if x<=-12 else x)\n",
    "\n",
    "test['TIME_DIFFERENCE'] = test['ATA_LT'] - test['hour'] #시차 계산\n",
    "test['TIME_DIFFERENCE'] = test['TIME_DIFFERENCE'].apply(lambda x: x+24 if x<=-12 else x)\n",
    "\n",
    "# local의 datetime 생성\n",
    "def add_time_difference(row):\n",
    "    return row['ATA'] + timedelta(hours=row['TIME_DIFFERENCE'])\n",
    "\n",
    "train['NEW_TIME'] = train.apply(add_time_difference, axis=1)\n",
    "test['NEW_TIME'] = test.apply(add_time_difference, axis=1)\n",
    "\n",
    "# datetime을 여러 파생 변수로 변환\n",
    "for df in [train, test]:\n",
    "    df['year'] = df['NEW_TIME'].dt.year\n",
    "    df['month'] = df['NEW_TIME'].dt.month\n",
    "    df['day'] = df['NEW_TIME'].dt.day\n",
    "    df['hour'] = df['NEW_TIME'].dt.hour\n",
    "    df['minute'] = df['NEW_TIME'].dt.minute\n",
    "    df['weekday'] = df['NEW_TIME'].dt.weekday\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "## Categorical 컬럼 인코딩\n",
    "categorical_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
    "encoders = {}\n",
    "\n",
    "for feature in tqdm(categorical_features, desc=\"Encoding features\"):\n",
    "    le = LabelEncoder()\n",
    "    train[feature] = le.fit_transform(train[feature].astype(str))\n",
    "    le_classes_set = set(le.classes_)\n",
    "    test[feature] = test[feature].map(lambda s: '-1' if s not in le_classes_set else s)\n",
    "    le_classes = le.classes_.tolist()\n",
    "    bisect.insort_left(le_classes, '-1')\n",
    "    le.classes_ = np.array(le_classes)\n",
    "    test[feature] = le.transform(test[feature].astype(str))\n",
    "    encoders[feature] = le\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "##결측치 처리\n",
    "#BREADTH, DEPTH 등 선박의 정보가 없는 356484번째 데이터 하나 삭제\n",
    "train.drop(356484, axis=0, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#########################################################\n",
    "##스케일링\n",
    "minmax_columns = ['GT', 'DEADWEIGHT'] #너어어무 범위 커서 스케일링........\n",
    "mms = MinMaxScaler(feature_range = (0,400))\n",
    "mms.fit(train[minmax_columns])\n",
    "train[minmax_columns] = mms.transform(train[minmax_columns])\n",
    "test[minmax_columns] = mms.transform(test[minmax_columns])\n",
    "##########################################################\n",
    "\n",
    "##피처 생성\n",
    "#선박 평균 수명은 25~30년 이라고 함.\n",
    "train['BUILT_old'] = np.where(train['BUILT'] > 25, 1, 0) #노선: 25년 초과면 1 아니면 0\n",
    "test['BUILT_old'] = np.where(test['BUILT'] > 25, 1, 0)\n",
    "\n",
    "#DIST 0인거 있음 (0 유무) => binary\n",
    "train['DIST_CATE'] = (train['DIST'] > 0).astype(int)\n",
    "test['DIST_CATE'] = (test['DIST'] > 0).astype(int)\n",
    "\n",
    "# 1000개 넘는 선박 소유주만 select => binary\n",
    "train['SHIPMANAGER_RICH'] = np.where(train['SHIPMANAGER'] > 1000, 1, 0)\n",
    "test['SHIPMANAGER_RICH'] = np.where(test['SHIPMANAGER'] > 1000, 1, 0)\n",
    "\n",
    "#\n",
    "train['bn_cate'] = np.where(train['BN'] < 3, 0, np.where(train['BN'] <= 6, 1, 2))\n",
    "test['bn_cate'] = np.where(test['BN'] < 3, 0, np.where(test['BN'] <= 6, 1, 2))\n",
    "\n",
    "#폭염(섭씨 35도 이상)\n",
    "train['hot'] = np.where(train['AIR_TEMPERATURE'] >= 35, 1, 0)\n",
    "test['hot'] = np.where(test['AIR_TEMPERATURE'] >= 35, 1, 0)\n",
    "\n",
    "#한파(섭씨 -15도 이하)\n",
    "train['cold'] = np.where(train['AIR_TEMPERATURE'] <= -15, 1, 0)\n",
    "test['cold'] = np.where(test['AIR_TEMPERATURE'] <= -15, 1, 0)\n",
    "\n",
    "#주말 여부\n",
    "train['weekend'] = np.where(train['weekday'] >= 5, 1, 0)\n",
    "test['weekend'] = np.where(test['weekday'] >= 5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f11b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATA</th>\n",
       "      <th>TIME_DIFFERENCE</th>\n",
       "      <th>NEW_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-17 21:29:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-12-18 05:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-23 06:59:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-09-23 12:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-03 22:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-02-04 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-17 04:02:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-17 13:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26 07:51:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-01-26 15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391933</th>\n",
       "      <td>2017-06-06 05:02:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-06-06 14:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391934</th>\n",
       "      <td>2019-10-16 00:36:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-16 08:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391935</th>\n",
       "      <td>2021-03-23 22:35:00</td>\n",
       "      <td>-4</td>\n",
       "      <td>2021-03-23 18:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391936</th>\n",
       "      <td>2015-01-08 07:15:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-01-08 15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391937</th>\n",
       "      <td>2015-06-08 23:30:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-06-09 07:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391938 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ATA  TIME_DIFFERENCE            NEW_TIME\n",
       "0      2018-12-17 21:29:00                8 2018-12-18 05:29:00\n",
       "1      2014-09-23 06:59:00                6 2014-09-23 12:59:00\n",
       "2      2015-02-03 22:00:00                8 2015-02-04 06:00:00\n",
       "3      2020-01-17 04:02:00                9 2020-01-17 13:02:00\n",
       "4      2020-01-26 07:51:00                8 2020-01-26 15:51:00\n",
       "...                    ...              ...                 ...\n",
       "391933 2017-06-06 05:02:00                9 2017-06-06 14:02:00\n",
       "391934 2019-10-16 00:36:00                8 2019-10-16 08:36:00\n",
       "391935 2021-03-23 22:35:00               -4 2021-03-23 18:35:00\n",
       "391936 2015-01-08 07:15:00                8 2015-01-08 15:15:00\n",
       "391937 2015-06-08 23:30:00                8 2015-06-09 07:30:00\n",
       "\n",
       "[391938 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TIME_DIFFERENCe, NEW_TIME 피처 생성된 것 확인\n",
    "train.loc[:,['ATA', 'TIME_DIFFERENCE', 'NEW_TIME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf61dbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.51039407518398\n",
      "48.83009308984127\n",
      "49.895614996281715\n",
      "50.7009322251558\n",
      "55.44520602841297\n",
      "117.59785645048761\n",
      "120.81260596205672\n"
     ]
    }
   ],
   "source": [
    "print(train[train['weekday'] == 0]['CI_HOUR'].mean())\n",
    "print(train[train['weekday'] == 1]['CI_HOUR'].mean())\n",
    "print(train[train['weekday'] == 2]['CI_HOUR'].mean())\n",
    "print(train[train['weekday'] == 3]['CI_HOUR'].mean())\n",
    "print(train[train['weekday'] == 4]['CI_HOUR'].mean())\n",
    "print(train[train['weekday'] == 5]['CI_HOUR'].mean())\n",
    "print(train[train['weekday'] == 6]['CI_HOUR'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f941148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#쓸모 없는거 drop\n",
    "train.drop(columns=['ATA', 'NEW_TIME', 'ATA_LT', 'ID', 'DEPTH', 'DRAUGHT', 'minute', 'U_WIND', 'V_WIND', 'AIR_TEMPERATURE', 'BN', 'BREADTH', 'BUILT', 'SHIPMANAGER', 'FLAG'], axis=1, inplace=True)\n",
    "test.drop(columns=['ATA', 'NEW_TIME', 'ATA_LT', 'ID', 'DEPTH', 'DRAUGHT', 'minute', 'U_WIND', 'V_WIND', 'AIR_TEMPERATURE', 'BN', 'BREADTH', 'BUILT', 'SHIPMANAGER', 'FLAG'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07ffba-81a8-4d29-b49d-ddd51cc56150",
   "metadata": {},
   "source": [
    "## 모델 선택 및 최적화 with autogluon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc2fbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test 데이터셋\n",
    "train = TabularDataset(train)\n",
    "test = TabularDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b09fe84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240116_103039\\\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (391938 samples, 53.3 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240116_103039\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "Disk Space Avail:   299.25 GB / 510.55 GB (58.6%)\n",
      "Train Data Rows:    391938\n",
      "Train Data Columns: 21\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2159.130556, 0.0, 61.94099, 170.80975)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6825.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 50.17 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  5 | ['DIST', 'DEADWEIGHT', 'GT', 'LENGTH', 'PORT_SIZE']\n",
      "\t\t('int', [])   : 16 | ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'hour', 'TIME_DIFFERENCE', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  5 | ['DIST', 'DEADWEIGHT', 'GT', 'LENGTH', 'PORT_SIZE']\n",
      "\t\t('int', [])       : 10 | ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'hour', 'TIME_DIFFERENCE', ...]\n",
      "\t\t('int', ['bool']) :  6 | ['BUILT_old', 'DIST_CATE', 'SHIPMANAGER_RICH', 'hot', 'cold', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t21 features in original data used to generate 21 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.11 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.68s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 388018, Val Rows: 3920\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-59.1307\t = Validation score   (-mean_absolute_error)\n",
      "\t4.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-58.8904\t = Validation score   (-mean_absolute_error)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 55.746\n",
      "[2000]\tvalid_set's l1: 55.2087\n",
      "[3000]\tvalid_set's l1: 55.0028\n",
      "[4000]\tvalid_set's l1: 54.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-54.9228\t = Validation score   (-mean_absolute_error)\n",
      "\t12.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 54.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-54.9095\t = Validation score   (-mean_absolute_error)\n",
      "\t4.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-55.8354\t = Validation score   (-mean_absolute_error)\n",
      "\t67.26s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-55.7484\t = Validation score   (-mean_absolute_error)\n",
      "\t150.75s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-55.4189\t = Validation score   (-mean_absolute_error)\n",
      "\t24.73s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\tException occured in `AgSaveModelCallback` when calling event `after_epoch`:\n",
      "\tmodule 'torch' has no attribute '_utils'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 327, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params[\"lr\"], cbs=callbacks)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\callback\\schedule.py\", line 119, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 264, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 253, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 201, in _with_events\n",
      "    self(f'after_{event_type}');  final()\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 172, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 176, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\callback\\core.py\", line 62, in __call__\n",
      "    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\callback\\core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\callbacks.py\", line 103, in after_epoch\n",
      "    self._save(f\"{self.fname}\")\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\callbacks.py\", line 87, in _save\n",
      "    self.last_saved_path = self.learn.save(name, with_opt=self.with_opt)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 408, in save\n",
      "    save_model(file, self.model, getattr(self,'opt',None), **kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py\", line 44, in save_model\n",
      "    torch.save(state, file, pickle_protocol=pickle_protocol, **torch_save_kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py\", line 619, in save\n",
      "    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\serialization.py\", line 831, in _save\n",
      "    pickler.dump(obj)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_tensor.py\", line 213, in __reduce_ex__\n",
      "    state = torch._utils._get_obj_state(self)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\__init__.py\", line 1833, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: Exception occured in `AgSaveModelCallback` when calling event `after_epoch`:\n",
      "\tmodule 'torch' has no attribute '_utils'\n",
      "Fitting model: XGBoost ...\n",
      "\t-51.5009\t = Validation score   (-mean_absolute_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tmodule 'torch' has no attribute '_utils'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 195, in _fit\n",
      "    self.optimizer = self._init_optimizer(**optimizer_kwargs)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 552, in _init_optimizer\n",
      "    optimizer = torch.optim.Adam(params=self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\adam.py\", line 45, in __init__\n",
      "    super().__init__(params, defaults)\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 266, in __init__\n",
      "    self.add_param_group(cast(dict, param_group))\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_compile.py\", line 22, in inner\n",
      "    import torch._dynamo\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 2, in <module>\n",
      "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py\", line 24, in <module>\n",
      "    from . import config\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\_dynamo\\config.py\", line 51, in <module>\n",
      "    torch._utils.is_compiling: True,\n",
      "  File \"c:\\Users\\yebin\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\__init__.py\", line 1833, in __getattr__\n",
      "    raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\n",
      "AttributeError: module 'torch' has no attribute '_utils'\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 53.8705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-53.7546\t = Validation score   (-mean_absolute_error)\n",
      "\t8.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-49.8272\t = Validation score   (-mean_absolute_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 290.98s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240116_103039\\\")\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "predictor = TabularPredictor(label='CI_HOUR', eval_metric='mean_absolute_error').fit(train, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1f4cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.588998</td>\n",
       "      <td>-58.890378</td>\n",
       "      <td>10.368644</td>\n",
       "      <td>0.114366</td>\n",
       "      <td>1.426626</td>\n",
       "      <td>10.368644</td>\n",
       "      <td>0.114366</td>\n",
       "      <td>1.426626</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-29.484355</td>\n",
       "      <td>-55.835415</td>\n",
       "      <td>1.765887</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>67.257278</td>\n",
       "      <td>1.765887</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>67.257278</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-33.239833</td>\n",
       "      <td>-55.418901</td>\n",
       "      <td>1.612748</td>\n",
       "      <td>0.047514</td>\n",
       "      <td>24.733392</td>\n",
       "      <td>1.612748</td>\n",
       "      <td>0.047514</td>\n",
       "      <td>24.733392</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-42.991240</td>\n",
       "      <td>-53.754648</td>\n",
       "      <td>2.903282</td>\n",
       "      <td>0.034509</td>\n",
       "      <td>8.325534</td>\n",
       "      <td>2.903282</td>\n",
       "      <td>0.034509</td>\n",
       "      <td>8.325534</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-45.292594</td>\n",
       "      <td>-49.827193</td>\n",
       "      <td>21.350579</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>90.624560</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157093</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-48.213185</td>\n",
       "      <td>-59.130725</td>\n",
       "      <td>10.861240</td>\n",
       "      <td>0.122989</td>\n",
       "      <td>4.832691</td>\n",
       "      <td>10.861240</td>\n",
       "      <td>0.122989</td>\n",
       "      <td>4.832691</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-50.495000</td>\n",
       "      <td>-54.922798</td>\n",
       "      <td>5.955230</td>\n",
       "      <td>0.063512</td>\n",
       "      <td>12.681751</td>\n",
       "      <td>5.955230</td>\n",
       "      <td>0.063512</td>\n",
       "      <td>12.681751</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-50.753731</td>\n",
       "      <td>-51.500940</td>\n",
       "      <td>0.322032</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.776278</td>\n",
       "      <td>0.322032</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.776278</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-50.798143</td>\n",
       "      <td>-54.909507</td>\n",
       "      <td>1.598030</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>4.058838</td>\n",
       "      <td>1.598030</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>4.058838</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-51.668690</td>\n",
       "      <td>-55.748404</td>\n",
       "      <td>0.230105</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>150.746153</td>\n",
       "      <td>0.230105</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>150.746153</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0       KNeighborsDist   -0.588998 -58.890378       10.368644       0.114366   \n",
       "1      RandomForestMSE  -29.484355 -55.835415        1.765887       0.062011   \n",
       "2        ExtraTreesMSE  -33.239833 -55.418901        1.612748       0.047514   \n",
       "3        LightGBMLarge  -42.991240 -53.754648        2.903282       0.034509   \n",
       "4  WeightedEnsemble_L2  -45.292594 -49.827193       21.350579       0.283400   \n",
       "5       KNeighborsUnif  -48.213185 -59.130725       10.861240       0.122989   \n",
       "6           LightGBMXT  -50.495000 -54.922798        5.955230       0.063512   \n",
       "7              XGBoost  -50.753731 -51.500940        0.322032       0.009001   \n",
       "8             LightGBM  -50.798143 -54.909507        1.598030       0.017690   \n",
       "9             CatBoost  -51.668690 -55.748404        0.230105       0.013998   \n",
       "\n",
       "     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0    1.426626                10.368644                0.114366   \n",
       "1   67.257278                 1.765887                0.062011   \n",
       "2   24.733392                 1.612748                0.047514   \n",
       "3    8.325534                 2.903282                0.034509   \n",
       "4   90.624560                 0.035505                0.000000   \n",
       "5    4.832691                10.861240                0.122989   \n",
       "6   12.681751                 5.955230                0.063512   \n",
       "7    0.776278                 0.322032                0.009001   \n",
       "8    4.058838                 1.598030                0.017690   \n",
       "9  150.746153                 0.230105                0.013998   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           1.426626            1       True          2  \n",
       "1          67.257278            1       True          5  \n",
       "2          24.733392            1       True          7  \n",
       "3           8.325534            1       True          9  \n",
       "4           0.157093            2       True         10  \n",
       "5           4.832691            1       True          1  \n",
       "6          12.681751            1       True          3  \n",
       "7           0.776278            1       True          8  \n",
       "8           4.058838            1       True          4  \n",
       "9         150.746153            1       True          6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 리더보드 출력\n",
    "predictor.leaderboard(train, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53ef9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test)\n",
    "y_pred = pd.DataFrame(y_pred, columns=['CI_HOUR'])\n",
    "y_pred['CI_HOUR'] = y_pred['CI_HOUR'].apply(lambda x: max(0, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34eb37-f25e-4988-b3c9-67a760839bca",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71c8ce53-c8ef-4728-9b9e-16790b158afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['CI_HOUR'] = y_pred['CI_HOUR']\n",
    "submit.to_csv('./change_time_autogluon.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa982866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
